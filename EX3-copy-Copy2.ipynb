{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf6ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ba6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, TFRobertaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4d628",
   "metadata": {},
   "source": [
    "## 1. overall extraction procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89fc946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(file):\n",
    "    # parse the corpus\n",
    "    soup = BeautifulSoup(file, \"xml\")\n",
    "    # extract all texts\n",
    "    texts = soup.find_all(\"text\")\n",
    "    # filter the train data\n",
    "    data = []\n",
    "    for text in texts:\n",
    "        if exclude_train_data(text) == True:\n",
    "            pass\n",
    "        else:\n",
    "            sub_data = label_extraction(text)\n",
    "            data += sub_data\n",
    "    # transfer data to frame\n",
    "    corpusdata = pd.DataFrame.from_records(data, columns = [\"sentence\",\"word\",\"pos\",\"label\",\"type\",\"subtype\",\"function\"])\n",
    "    # add tags\n",
    "    get_tag(corpusdata)\n",
    "    # add local\n",
    "    get_local(corpusdata)\n",
    "    return corpusdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d652b",
   "metadata": {},
   "source": [
    "### subextraction: words in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf4c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_extraction(text):\n",
    "    # extract all sentence from a text\n",
    "    sents = text.find_all(\"s\")\n",
    "    data = []\n",
    "    for sent in sents:\n",
    "        # extract all the tokens\n",
    "        for token in sent.find_all(\"w\"):\n",
    "            # check whether there is any token labeled as metaphorical\n",
    "            if token.find(\"seg\"):\n",
    "                # make a full list of metaphorical words\n",
    "                mets_list = token.find_all(\"seg\")\n",
    "                # set indice: 1 for metaphor\n",
    "                met = 1\n",
    "                for m in mets_list:\n",
    "                    # check whether subtype is labeled\n",
    "                    if \"subtype\" in m.attrs.keys():\n",
    "                        # define subtype\n",
    "                        _subtype = m.attrs[\"subtype\"]\n",
    "                    else:\n",
    "                        _subtype = \"None\"\n",
    "                    # define type and function\n",
    "                    _type, _function = m.attrs[\"type\"], m.attrs[\"function\"]\n",
    "            else:\n",
    "                # when the token is not labeled as metaphorical\n",
    "                met = 0\n",
    "                _type = \"None\"\n",
    "                _subtype = \"None\"\n",
    "                _function = \"None\"\n",
    "            # extract the lemma and POS tag of the token\n",
    "            _lemma, _pos = token.attrs[\"lemma\"], token.attrs[\"type\"]\n",
    "            # clean the marks in the sentence\n",
    "            sentence = re.sub('[\\n\\s]+',' ', sent.text)\n",
    "            # pack the sentence, the word and its type and function together\n",
    "            data.append((sentence,_lemma,_pos,met,_type,_subtype,_function))\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e048a4f",
   "metadata": {},
   "source": [
    "### subextraction: filter train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c2fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_train_data(text):\n",
    "    # id of all the texts used for training\n",
    "    training_partition = [\n",
    "    'a1e-fragment01',\n",
    "    'a1f-fragment06',\n",
    "    'a1f-fragment07',\n",
    "    'a1f-fragment08',\n",
    "    'a1f-fragment09',\n",
    "    'a1f-fragment10',\n",
    "    'a1f-fragment11',\n",
    "    'a1f-fragment12',\n",
    "    'a1g-fragment26',\n",
    "    'a1g-fragment27',\n",
    "    'a1h-fragment05',\n",
    "    'a1h-fragment06',\n",
    "    'a1j-fragment34',\n",
    "    'a1k-fragment02',\n",
    "    'a1l-fragment01',\n",
    "    'a1m-fragment01',\n",
    "    'a1n-fragment09',\n",
    "    'a1n-fragment18',\n",
    "    'a1p-fragment01',\n",
    "    'a1p-fragment03',\n",
    "    'a1x-fragment03',\n",
    "    'a1x-fragment04',\n",
    "    'a1x-fragment05',\n",
    "    'a2d-fragment05',\n",
    "    'a38-fragment01',\n",
    "    'a39-fragment01',\n",
    "    'a3c-fragment05',\n",
    "    'a3e-fragment03',\n",
    "    'a3k-fragment11',\n",
    "    'a3p-fragment09',\n",
    "    'a4d-fragment02',\n",
    "    'a6u-fragment02',\n",
    "    'a7s-fragment03',\n",
    "    'a7y-fragment03',\n",
    "    'a80-fragment15',\n",
    "    'a8m-fragment02',\n",
    "    'a8n-fragment19',\n",
    "    'a8r-fragment02',\n",
    "    'a8u-fragment14',\n",
    "    'a98-fragment03',\n",
    "    'a9j-fragment01',\n",
    "    'ab9-fragment03',\n",
    "    'ac2-fragment06',\n",
    "    'acj-fragment01',\n",
    "    'ahb-fragment51',\n",
    "    'ahc-fragment60',\n",
    "    'ahf-fragment24',\n",
    "    'ahf-fragment63',\n",
    "    'ahl-fragment02',\n",
    "    'ajf-fragment07',\n",
    "    'al0-fragment06',\n",
    "    'al2-fragment23',\n",
    "    'al5-fragment03',\n",
    "    'alp-fragment01',\n",
    "    'amm-fragment02',\n",
    "    'as6-fragment01',\n",
    "    'as6-fragment02',\n",
    "    'b1g-fragment02',\n",
    "    'bpa-fragment14',\n",
    "    'c8t-fragment01',\n",
    "    'cb5-fragment02',\n",
    "    'ccw-fragment03',\n",
    "    'cdb-fragment02',\n",
    "    'cdb-fragment04',\n",
    "    'clp-fragment01',\n",
    "    'crs-fragment01',\n",
    "    'ea7-fragment03',\n",
    "    'ew1-fragment01',\n",
    "    'fef-fragment03',\n",
    "    'fet-fragment01',\n",
    "    'fpb-fragment01',\n",
    "    'g0l-fragment01',\n",
    "    'kb7-fragment10',\n",
    "    'kbc-fragment13',\n",
    "    'kbd-fragment07',\n",
    "    'kbh-fragment01',\n",
    "    'kbh-fragment02',\n",
    "    'kbh-fragment03',\n",
    "    'kbh-fragment09',\n",
    "    'kbh-fragment41',\n",
    "    'kbj-fragment17',\n",
    "    'kbp-fragment09',\n",
    "    'kbw-fragment04',\n",
    "    'kbw-fragment11',\n",
    "    'kbw-fragment17',\n",
    "    'kbw-fragment42',\n",
    "    'kcc-fragment02',\n",
    "    'kcf-fragment14',\n",
    "    'kcu-fragment02',\n",
    "    'kcv-fragment42']\n",
    "    # whether the text has attributions\n",
    "    if text.attrs is not None:\n",
    "        # whether it's in train set\n",
    "        if 'xml:id' in text.attrs.keys():\n",
    "            if text.attrs['xml:id'] in training_partition:\n",
    "                # block futher extraction\n",
    "                x = True\n",
    "            else:\n",
    "                # go on to extract sentences\n",
    "                x = False\n",
    "        else:\n",
    "            x = True\n",
    "    else:\n",
    "        x = True\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced8c16",
   "metadata": {},
   "source": [
    "### subextraction: Penn Treebank POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd93a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(data):\n",
    "    # make a list of words extracted from corpus\n",
    "    words = list(data[\"word\"])\n",
    "    # alpply pos tag to list\n",
    "    tags = [x[1] for x in nltk.pos_tag(words)]\n",
    "    # convert list to column\n",
    "    data[\"tag\"] = tags\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d03ead5",
   "metadata": {},
   "source": [
    "### subextraction: local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f12d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local(data):\n",
    "    local = []\n",
    "    # get sentences and tokens\n",
    "    sentences = list(data['sentence'])\n",
    "    words = list(data['word'])\n",
    "    # for each sentence\n",
    "    for i in range(len(sentences)):\n",
    "        flag = 0\n",
    "        w = words[i]\n",
    "        # split the sentence by comma\n",
    "        subsent = sentences[i].split(',')\n",
    "        original_len = len(local)\n",
    "        for t in range(len(subsent)):\n",
    "            nex = max((i+1),(len(words) -1))\n",
    "            # whether the word is in this part\n",
    "            if w in subsent[t] and flag == 0:\n",
    "                local.extend([subsent[t]])\n",
    "                flag = 1\n",
    "        # to avoid mismatch \n",
    "        if len(local) == original_len:\n",
    "            local.extend([subsent[0]])\n",
    "    data['local'] = local\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf05af7",
   "metadata": {},
   "source": [
    "## 2. Prepare test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca99e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get directory\n",
    "corpus_root = os.getcwd() + \"/\" + \"VUAMC.xml\"\n",
    "# read file\n",
    "file = open(corpus_root, encoding = \"utf-8\").read()\n",
    "# get whole test set\n",
    "corpus = parse_xml(file)\n",
    "# save the test set\n",
    "corpus.to_csv(r'./test_data.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7540c7",
   "metadata": {},
   "source": [
    "## 3. Get prediction (two alternatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7884e31",
   "metadata": {},
   "source": [
    "### (1) with pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba64327",
   "metadata": {},
   "source": [
    "#### Complie test set into transformers inputs (modified version of original DeepMet code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaca86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compilation(data):\n",
    "    # regulate format of test set\n",
    "    def preprocssing(x):\n",
    "        x = str(x)\n",
    "        x = '\"'+x+'\"'\n",
    "        return x\n",
    "    def _convert_to_transformer_inputs(instance, instance2, tokenizer, max_sequence_length):\n",
    "        def return_id(str1, str2, truncation_strategy, length):\n",
    "            inputs = tokenizer.encode_plus(str1, str2,\n",
    "                                       add_special_tokens=True,\n",
    "                                       max_length=length,\n",
    "                                       truncation_strategy=truncation_strategy,\n",
    "                                       return_token_type_ids=True)\n",
    "            input_ids = inputs[\"input_ids\"]\n",
    "            input_masks = [1] * len(input_ids)\n",
    "            input_segments = inputs[\"token_type_ids\"]\n",
    "            padding_length = length - len(input_ids)\n",
    "            padding_id = tokenizer.pad_token_id\n",
    "            input_ids = input_ids + ([padding_id] * padding_length)\n",
    "            input_masks = input_masks + ([0] * padding_length)\n",
    "            input_segments = input_segments + ([0] * padding_length)\n",
    "            return [input_ids, input_masks, input_segments]\n",
    "        input_ids, input_masks, input_segments = return_id(\n",
    "            instance, None, 'longest_first', max_sequence_length)\n",
    "        input_ids2, input_masks2, input_segments2 = return_id(\n",
    "            instance2, None, 'longest_first', max_sequence_length)\n",
    "        return [input_ids, input_masks, input_segments,\n",
    "            input_ids2, input_masks2, input_segments2]\n",
    "    # transfer test set into arrays\n",
    "    def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
    "        input_ids, input_masks, input_segments = [], [], []\n",
    "        input_ids2, input_masks2, input_segments2 = [], [], []\n",
    "        for _, instance in df[columns].iterrows():\n",
    "            ids, masks, segments, ids2, masks2, segments2 = \\\n",
    "                _convert_to_transformer_inputs(str(instance.sentence), str(instance.sentence2), tokenizer, max_sequence_length)\n",
    "            input_ids.append(ids)\n",
    "            input_masks.append(masks)\n",
    "            input_segments.append(segments)\n",
    "            input_ids2.append(ids2)\n",
    "            input_masks2.append(masks2)\n",
    "            input_segments2.append(segments2)\n",
    "        return [np.asarray(input_ids, dtype=np.int32),\n",
    "                np.asarray(input_masks, dtype=np.int32),\n",
    "                np.asarray(input_segments, dtype=np.int32),\n",
    "                np.asarray(input_ids2, dtype=np.int32),\n",
    "                np.asarray(input_masks2, dtype=np.int32),\n",
    "                np.asarray(input_segments2, dtype=np.int32)]\n",
    "\n",
    "    # complie test data in format: sentence, token, POS, tag, local, so as to fit transformers input\n",
    "    def refomulate_test_set(test):\n",
    "        test['sentence'] = test.sentence.apply(lambda x: preprocssing(x)) \\\n",
    "                       + \"[SEP]\" + test.word.apply(lambda x: preprocssing(x)) \\\n",
    "                       + \"[SEP]\" + test.pos.apply(lambda x: preprocssing(x)) \\\n",
    "                       + \"[SEP]\" + test.tag.apply(lambda x: preprocssing(x))\n",
    "        test['sentence2'] = test.local.apply(lambda x: preprocssing(x)) \\\n",
    "                        + \"[SEP]\" + test.word.apply(lambda x: preprocssing(x)) \\\n",
    "                        + \"[SEP]\" + test.pos.apply(lambda x: preprocssing(x)) \\\n",
    "                        + \"[SEP]\" + test.tag.apply(lambda x: preprocssing(x))\n",
    "        return test\n",
    "\n",
    "    test = refomulate_test_set(data)\n",
    "\n",
    "    input_categories = [\"sentence\",\"sentence2\"]\n",
    "    # define tokenizer\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    # maximal sequence length is set as 64\n",
    "    test_inputs = compute_input_arrays(test, input_categories, tokenizer, 128)\n",
    "    return test_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc256cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the test data\n",
    "test_inputs = compilation(corpus)\n",
    "model_dir = r'./my_model.h5'\n",
    "# set TFRobertaModel in custom scope \n",
    "with tf.keras.utils.custom_object_scope({'TFRobertaModel': TFRobertaModel}):\n",
    "    # load model\n",
    "    model = tf.keras.models.load_model(model_dir)\n",
    "# predict\n",
    "pred = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87768c75",
   "metadata": {},
   "source": [
    "### (2) directly read the outcome we provide (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96db893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv('./predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a82fd5",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c54945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of direct metaphors:  0.5\n",
      "Recall of indirect metaphors:  0.729129397734049\n",
      "Recall of borderline cases:  0.5560675883256528\n",
      "Recall of clear cases:  0.7386032977691561\n",
      "F1 score:  0.7324717765894236 Recall:  0.7212227585198187\n"
     ]
    }
   ],
   "source": [
    "# read test data\n",
    "data = pd.read_csv(r'./test_data.csv')\n",
    "# reform and unite csv files\n",
    "data['predict'] = list(pred['predict'])\n",
    "\n",
    "label_direct = []\n",
    "pred_direct = []\n",
    "label_indirect = []\n",
    "pred_indirect = []\n",
    "label_border = []\n",
    "pred_border = []\n",
    "label_clear = []\n",
    "pred_clear = []\n",
    "\n",
    "# extract predication and label\n",
    "def get_pred_label(pred,label,row):\n",
    "    pred.append(row[1]['predict'])\n",
    "    label.append(row[1]['label'])\n",
    "    return pred, label\n",
    "    \n",
    "    \n",
    "# get each row\n",
    "for row in data.iterrows():\n",
    "    # check label for indirect metaphor\n",
    "    if row[1]['type'] == 'met':\n",
    "        get_pred_label(pred_indirect,label_indirect,row)\n",
    "    # direct metahpor\n",
    "    elif row[1]['type'] == 'lit':\n",
    "        get_pred_label(pred_direct,label_direct,row)\n",
    "    # borderline cases\n",
    "    if row[1]['subtype'] == 'WIDLII':\n",
    "        get_pred_label(pred_border,label_border,row)\n",
    "    # clear cases\n",
    "    elif row[1]['type'] != 'None' and row[1]['subtype'] != 'WIDLII':\n",
    "        get_pred_label(pred_clear,label_clear,row)\n",
    "\n",
    "# evaluate\n",
    "# direct\n",
    "recall_direct = recall_score(label_direct, pred_direct)\n",
    "print(\"Recall of direct metaphors: \", recall_direct)\n",
    "# indirect\n",
    "recall_indirect = recall_score(label_indirect, pred_indirect)\n",
    "print(\"Recall of indirect metaphors: \", recall_indirect)\n",
    "# borderline\n",
    "recall_borderline = recall_score(label_border, pred_border)\n",
    "print(\"Recall of borderline cases: \", recall_borderline)\n",
    "# clear\n",
    "recall_clear = recall_score(label_clear, pred_clear)\n",
    "print(\"Recall of clear cases: \", recall_clear)\n",
    "\n",
    "# overall f1-score and recall\n",
    "Recall = recall_score(list(data['label']),list(data['predict']))\n",
    "F1score = f1_score(list(data['label']),list(data['predict']))\n",
    "print('F1 score: ',F1score, \"Recall: \", Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ed742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
